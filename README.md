# Scribe - MP3 Transcription & Summary CLI Tool

A clean architecture CLI application that transcribes audio files using OpenAI Whisper (local processing) and generates summaries with action items using Google Gemini API.

## Quick Start

```bash
# 1. Install ffmpeg (REQUIRED - see Installation section)
sudo apt-get install -y ffmpeg  # Ubuntu/Debian
# OR: brew install ffmpeg        # macOS

# 2. Install Python dependencies
pip install -r requirements.txt

# 3. Set up Gemini API key
cp .env.example .env
# Edit .env and add your GEMINI_API_KEY

# 4. Run transcription
python transcriber.py your_audio.mp3
```

## Features

- ğŸ™ï¸ **Local Transcription**: Uses OpenAI Whisper for 100% free, local audio transcription
- ğŸ¤– **AI Summarization**: Leverages Google Gemini API to generate conversation summaries and extract action items
- ğŸ—ï¸ **Clean Architecture**: Follows Ardalis clean architecture principles with clear separation of concerns
- âœ… **Testable Core**: Business logic is fully tested and independent of infrastructure
- ğŸ“Š **Multiple Output Formats**: Save results as TXT, JSON, or Markdown
- âš™ï¸ **Flexible Models**: Choose from 5 Whisper model sizes (tiny to large)

## Architecture

This project follows **Clean Architecture** principles as advocated by Steve Smith (Ardalis):

```
src/
â”œâ”€â”€ core/                    # Core business logic (no external dependencies)
â”‚   â”œâ”€â”€ models/             # Domain models, commands, queries, AppResult
â”‚   â”œâ”€â”€ interfaces/         # Provider interfaces (abstractions)
â”‚   â””â”€â”€ services/           # Business logic services
â””â”€â”€ infrastructure/          # Implementation details
    â”œâ”€â”€ whisper_provider.py  # Whisper transcription implementation
    â”œâ”€â”€ gemini_provider.py   # Gemini summarization implementation
    â””â”€â”€ output_formatter.py  # Output formatting utilities
```

### Key Architecture Principles

1. âœ… **Dependency Rule**: Dependencies point inward towards Core
2. âœ… **Core Independence**: Core has minimal dependencies, no direct infrastructure references
3. âœ… **Interface Definitions**: Core defines interfaces, Infrastructure implements them
4. âœ… **Command/Query Pattern**: Services use command objects as inputs
5. âœ… **AppResult Pattern**: Services return consistent result objects with success/failure info
6. âœ… **Testability**: Core services are fully unit tested without infrastructure dependencies

## Installation

### Prerequisites

- Python 3.8 or higher
- pip
- **ffmpeg** (required by Whisper for audio processing)
- (Optional) GPU for faster transcription

### Setup

1. Clone the repository:
```bash
git clone https://github.com/michaelprosario/scribe.git
cd scribe
```

2. **Install ffmpeg** (required):
```bash
# Ubuntu/Debian
sudo apt-get update && sudo apt-get install -y ffmpeg

# macOS
brew install ffmpeg

# Windows
# Download from https://ffmpeg.org/download.html
```

3. Install Python dependencies:
```bash
pip install -r requirements.txt
```

4. Configure environment variables:
```bash
cp .env.example .env
# Edit .env and add your Gemini API key
```

5. Get your Gemini API key from: https://makersuite.google.com/app/apikey

## Usage

### Basic Usage

Transcribe and summarize an audio file:
```bash
python transcriber.py recording.mp3
```

### Advanced Usage

Choose a different Whisper model:
```bash
python transcriber.py recording.mp3 --model small
```

Skip summarization (transcription only):
```bash
python transcriber.py recording.mp3 --no-summary
```

Save output to a file:
```bash
# Text format
python transcriber.py recording.mp3 --output results.txt

# JSON format
python transcriber.py recording.mp3 --output results.json

# Markdown format
python transcriber.py recording.mp3 --output results.md
```

### Whisper Model Options

| Model | Size | Speed | Accuracy | RAM Required |
|-------|------|-------|----------|--------------|
| tiny  | ~75MB | Fastest | Lowest | ~1GB |
| base  | ~140MB | Fast | Good | ~1GB |
| small | ~460MB | Medium | Better | ~2GB |
| medium | ~1.5GB | Slow | High | ~5GB |
| large | ~3GB | Slowest | Best | ~10GB |

**Recommendation**: Start with `base` for a good balance of speed and accuracy.

## Testing

Run all unit tests:
```bash
python -m pytest tests/
```

Run tests with coverage:
```bash
python -m pytest tests/ --cov=src --cov-report=html
```

The core business logic has comprehensive unit tests that run without external dependencies.

## Project Structure

```
scribe/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                       # Core business logic
â”‚   â”‚   â”œâ”€â”€ models/                 # Domain models
â”‚   â”‚   â”‚   â”œâ”€â”€ app_result.py      # Result object pattern
â”‚   â”‚   â”‚   â”œâ”€â”€ commands.py        # Command/Query objects
â”‚   â”‚   â”‚   â”œâ”€â”€ transcription.py   # Transcription model
â”‚   â”‚   â”‚   â””â”€â”€ summary.py         # Summary model
â”‚   â”‚   â”œâ”€â”€ interfaces/             # Provider interfaces
â”‚   â”‚   â”‚   â”œâ”€â”€ transcription_provider.py
â”‚   â”‚   â”‚   â””â”€â”€ summarization_provider.py
â”‚   â”‚   â””â”€â”€ services/               # Business logic services
â”‚   â”‚       â”œâ”€â”€ transcription_service.py
â”‚   â”‚       â””â”€â”€ audio_processing_service.py
â”‚   â””â”€â”€ infrastructure/             # Implementation details
â”‚       â”œâ”€â”€ whisper_provider.py     # Whisper implementation
â”‚       â”œâ”€â”€ gemini_provider.py      # Gemini implementation
â”‚       â””â”€â”€ output_formatter.py     # Output formatting
â”œâ”€â”€ tests/                          # Unit tests
â”‚   â”œâ”€â”€ test_app_result.py
â”‚   â”œâ”€â”€ test_transcription_service.py
â”‚   â””â”€â”€ test_audio_processing_service.py
â”œâ”€â”€ prompt/                         # Architecture documentation
â”‚   â”œâ”€â”€ 001-cleanArchitecture
â”‚   â””â”€â”€ 002-baseRequirements
â”œâ”€â”€ transcriber.py                  # CLI entry point
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ .env.example                    # Environment variables template
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## Cost & Performance

### Transcription (Whisper)
- **Cost**: 100% FREE (runs locally)
- **First run**: Downloads model (~72MB for tiny, ~140MB for base, up to ~3GB for large)
- **Processing time**: 
  - `tiny` model: ~0.5-1x real-time (10min audio = ~5-10min processing on CPU)
  - `base` model: ~1-2x real-time (10min audio = ~10-20min processing on CPU)
  - Faster with GPU if available
- **Note**: Progress bar shown during model download and transcription

### Summarization (Gemini)
- **Cost**: Free tier available (60 requests/minute)
- **Processing time**: Usually < 5 seconds

## Troubleshooting

### "No such file or directory: 'ffmpeg'"
**Solution**: Install ffmpeg before running the transcriber:
```bash
# Ubuntu/Debian
sudo apt-get install -y ffmpeg

# macOS
brew install ffmpeg

# Windows - Download from https://ffmpeg.org/download.html
```

### "Gemini API key not provided"
**Solution**: Create a `.env` file with your API key:
```bash
cp .env.example .env
# Edit .env and add: GEMINI_API_KEY=your_actual_key_here
```

### "Audio file not found"
**Solution**: Use absolute path or verify file exists:
```bash
ls -l audio.mp3
python transcriber.py $(pwd)/audio.mp3
```

### "FP16 is not supported on CPU; using FP32 instead"
This is just a warning (not an error). Whisper automatically uses FP32 on CPU. You can safely ignore this message.

## Contributing

Contributions are welcome! This project follows clean architecture principles, so please ensure:

1. Core business logic remains independent of infrastructure
2. New services use command/query objects as inputs
3. Services return AppResult objects
4. Add unit tests for all core services
5. Infrastructure implementations follow defined interfaces

## License

MIT License - See LICENSE file for details

## Acknowledgments

- OpenAI Whisper for excellent local transcription
- Google Gemini for powerful AI summarization
- Steve Smith (Ardalis) for clean architecture guidance
CLI tool to transcribe mp3
